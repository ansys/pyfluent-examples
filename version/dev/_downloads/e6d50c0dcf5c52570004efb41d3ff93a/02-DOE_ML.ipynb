{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Design of Experiments and Machine Learning model building {#doe_ml}\n=========================================================\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Objective\n=========\n\nWater enters a Mixing Elbow from two Inlets; Hot (313 K) and Cold (293\nK) and exits from Outlet. Using PyFluent in the background, this example\nruns Design of Experiments with Cold Inlet Velocity and Hot Inlet\nVelocity as Input Parameters and Outlet Temperature as an Output\nParameter.\n\nResults can be visualized using a Response Surface. Finally, Supervised\nMachine Learning Regression Task is performed to build the ML Model.\n\nThis example demonstrates:\n\n-   Design of Experiment, Fluent setup and simulation using PyFluent.\n-   Building of Supervised Machine Learning Model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# sphinx_gallery_thumbnail_path = '_static/doe_ml_predictions_regression.png'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Import required libraries/modules\n=================================\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n\nimport ansys.fluent.core as pyfluent\nfrom ansys.fluent.core import examples\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport seaborn as sns\nimport tensorflow as tf\nfrom tensorflow import keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Specifying save path\n====================\n\n-   save\\_path can be specified as Path(\\\"E:/\\\",\n    \\\"pyfluent-examples-tests\\\") or\n-   Path(\\\"E:/pyfluent-examples-tests\\\") in a Windows machine for\n    example, or\n-   Path(\\\"\\~/pyfluent-examples-tests\\\") in Linux.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "save_path = Path(pyfluent.EXAMPLES_PATH)\n\nimport_filename = examples.download_file(\n    \"elbow.cas.h5\",\n    \"pyfluent/examples/DOE-ML-Mixing-Elbow\",\n    save_path=save_path,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Fluent Solution Setup\n=====================\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Launch Fluent session with solver mode\n======================================\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "solver = pyfluent.launch_fluent(\n    product_version=\"23.1.0\",\n    mode=\"solver\",\n    show_gui=False,\n    version=\"3d\",\n    precision=\"double\",\n    processor_count=2,\n)\nsolver.health_check_service.check_health()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Read case\n=========\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "solver.tui.file.read_case(import_filename)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Design of Experiments\n=====================\n\n-   Define Manual DOE as numpy arrays\n-   Run cases in sequence\n-   Populate results (Mass Weighted Average of Temperature at Outlet) in\n    resArr\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "coldVelArr = np.array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7])\nhotVelArr = np.array([0.8, 1, 1.2, 1.4, 1.6, 1.8, 2.0])\nresArr = np.zeros((coldVelArr.shape[0], hotVelArr.shape[0]))\n\nfor idx1, coldVel in np.ndenumerate(coldVelArr):\n    for idx2, hotVel in np.ndenumerate(hotVelArr):\n        solver.setup.boundary_conditions.velocity_inlet[\"cold-inlet\"].vmag = {\n            \"option\": \"value\",\n            \"value\": coldVel,\n        }\n\n        solver.setup.boundary_conditions.velocity_inlet[\"hot-inlet\"].vmag = {\n            \"option\": \"value\",\n            \"value\": hotVel,\n        }\n\n        solver.tui.solve.initialize.initialize_flow(\"yes\")\n        solver.tui.solve.iterate(200)\n\n        res_tui = solver.scheme_eval.exec(\n            (\n                \"(ti-menu-load-string \"\n                '\"/report/surface-integrals/mass-weighted-avg outlet () '\n                'temperature no\")',\n            )\n        )\n        resArr[idx1][idx2] = eval(res_tui.split(\" \")[-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Close the session\n=================\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "solver.exit()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot Response Surface using Plotly\n==================================\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig = go.Figure(data=[go.Surface(z=resArr.T, x=coldVelArr, y=hotVelArr)])\n\nfig.update_layout(\n    title={\n        \"text\": \"Mixing Elbow Response Surface\",\n        \"y\": 0.9,\n        \"x\": 0.5,\n        \"xanchor\": \"center\",\n        \"yanchor\": \"top\",\n    }\n)\n\nfig.update_layout(\n    scene=dict(\n        xaxis_title=\"Cold Inlet Vel (m/s)\",\n        yaxis_title=\"Hot Inlet Vel (m/s)\",\n        zaxis_title=\"Outlet Temperature (K)\",\n    ),\n    width=600,\n    height=600,\n    margin=dict(l=80, r=80, b=80, t=80),\n)\nfig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Supervised ML for a Regression Task\n===================================\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create Pandas Dataframe for ML Model Input\n==========================================\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "coldVelList = []\nhotVelList = []\nResultList = []\n\nfor idx1, coldVel in np.ndenumerate(coldVelArr):\n    for idx2, hotVel in np.ndenumerate(hotVelArr):\n        coldVelList.append(coldVel)\n        hotVelList.append(hotVel)\n        ResultList.append(resArr[idx1][idx2])\n\ntempDict = {\"coldVel\": coldVelList, \"hotVel\": hotVelList, \"Result\": ResultList}\n\ndf = pd.DataFrame.from_dict(tempDict)\n\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import PolynomialFeatures, StandardScaler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Using scikit-learn\n==================\n\n-   Prepare Features (X) and Label (y) using a Pre-Processing Pipeline\n-   Train-Test (80-20) Split\n-   Add Polynomial Features to improve ML Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "poly_features = PolynomialFeatures(degree=2, include_bias=False)\n\ntransformer1 = Pipeline(\n    [\n        (\"poly_features\", poly_features),\n        (\"std_scaler\", StandardScaler()),\n    ]\n)\n\n\nx_ct = ColumnTransformer(\n    [\n        (\"transformer1\", transformer1, [\"coldVel\", \"hotVel\"]),\n    ],\n    remainder=\"drop\",\n)\n\ntrain_set, test_set = train_test_split(df, test_size=0.2, random_state=42)\n\nX_train = x_ct.fit_transform(train_set)\nX_test = x_ct.fit_transform(test_set)\n\ny_train = train_set[\"Result\"]\ny_test = test_set[\"Result\"]\ny_train = np.ravel(y_train.T)\ny_test = np.ravel(y_test.T)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   Define functions for:\n-   Cross-Validation and Display Scores (scikit-learn)\n-   Training the Model (scikit-learn)\n-   Prediction on Unseen/Test Data (scikit-learn)\n-   Parity Plot (Matplotlib and Seaborn)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from pprint import pprint  # noqa: F401\n\nfrom sklearn.ensemble import RandomForestRegressor  # noqa: F401\nfrom sklearn.linear_model import LinearRegression  # noqa: F401\nfrom sklearn.metrics import r2_score\nfrom sklearn.model_selection import RepeatedKFold, cross_val_score\nfrom xgboost import XGBRegressor\n\nnp.set_printoptions(precision=2)\n\n\ndef display_scores(scores):\n    print(\"\\nCross-Validation Scores:\", scores)\n    print(\"Mean:%0.2f\" % (scores.mean()))\n    print(\"Std. Dev.:%0.2f\" % (scores.std()))\n\n\ndef fit_and_predict(model):\n    cv = RepeatedKFold(n_splits=5, n_repeats=3, random_state=42)\n    cv_scores = cross_val_score(\n        model, X_train, y_train, scoring=\"neg_mean_squared_error\", cv=cv\n    )\n    rmse_scores = np.sqrt(-cv_scores)\n    display_scores(rmse_scores)\n\n    model.fit(X_train, y_train)\n    train_predictions = model.predict(X_train)\n    test_predictions = model.predict(X_test)\n    print(train_predictions.shape[0])\n    print(\"\\n\\nCoefficient Of Determination\")\n    print(\"Train Data R2 Score: %0.3f\" % (r2_score(train_predictions, y_train)))\n    print(\"Test Data R2 Score: %0.3f\" % (r2_score(test_predictions, y_test)))\n    print(\n        \"\\n\\nPredictions - Ground Truth (Kelvin): \", (test_predictions - y_test), \"\\n\"\n    )\n    #    print(\"\\n\\nModel Parameters:\")\n    #    pprint(model.get_params())\n\n    com_train_set = train_set\n    com_test_set = test_set\n\n    train_list = []\n    for i in range(train_predictions.shape[0]):\n        train_list.append(\"Train\")\n\n    test_list = []\n    for i in range(test_predictions.shape[0]):\n        test_list.append(\"Test\")\n\n    com_train_set[\"Result\"] = train_predictions.tolist()\n    com_train_set[\"Set\"] = train_list\n    com_test_set[\"Result\"] = test_predictions.tolist()\n    com_test_set[\"Set\"] = test_list\n\n    df_combined = pd.concat([com_train_set, com_test_set])\n\n    df_combined.to_csv(\"PyFluent_Output.csv\", header=True, index=False)\n\n    fig = plt.figure(figsize=(12, 5))\n\n    fig.add_subplot(121)\n    sns.regplot(x=y_train, y=train_predictions, color=\"g\")\n    plt.title(\"Train Data\", fontsize=16)\n    plt.xlabel(\"Ground Truth\", fontsize=12)\n    plt.ylabel(\"Predictions\", fontsize=12)\n\n    fig.add_subplot(122)\n    sns.regplot(x=y_test, y=test_predictions, color=\"g\")\n    plt.title(\"Unseen Data\", fontsize=16)\n    plt.xlabel(\"Ground Truth\", fontsize=12)\n    plt.ylabel(\"Predictions\", fontsize=12)\n\n    plt.tight_layout()\n    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Select the Model from Linear, Random Forest or XGBoost\n======================================================\n\n-   Call fit\\_and\\_predict\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# model = LinearRegression()\nmodel = XGBRegressor(\n    n_estimators=100, max_depth=10, eta=0.3, subsample=0.8, random_state=42\n)\n# model = RandomForestRegressor(random_state=42)\n\nfit_and_predict(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Show graph\n==========\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![Regression Model Predictions](../../_static/doe_ml_predictions_regression.png){.align-center}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Regression Model Predictions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "3D Visualization of Model Predictions on Train & Test Set\n=========================================================\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"PyFluent_Output.csv\")\n\nfig = px.scatter_3d(df, x=\"coldVel\", y=\"hotVel\", z=\"Result\", color=\"Set\")\nfig.update_traces(marker=dict(size=4))\nfig.update_layout(legend=dict(yanchor=\"top\", y=1, xanchor=\"left\", x=0.0))\n\nfig.add_traces(go.Surface(z=resArr.T, x=coldVelArr, y=hotVelArr))\n\nfig.update_layout(\n    title={\n        \"text\": \"Mixing Elbow Response Surface\",\n        \"y\": 0.9,\n        \"x\": 0.5,\n        \"xanchor\": \"center\",\n        \"yanchor\": \"top\",\n    }\n)\n\nfig.update_layout(\n    scene=dict(\n        xaxis_title=\"Cold Inlet Vel (m/s)\",\n        yaxis_title=\"Hot Inlet Vel (m/s)\",\n        zaxis_title=\"Outlet Temperature (K)\",\n    ),\n    width=500,\n    height=500,\n    margin=dict(l=80, r=80, b=80, t=80),\n)\n\nfig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "TensorFlow and Keras Neural Network Regression\n==============================================\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"TensorFlow version is:\", tf.__version__)\nkeras.backend.clear_session()\nnp.random.seed(42)\ntf.random.set_seed(42)\n\nmodel = keras.models.Sequential(\n    [\n        keras.layers.Dense(\n            20,\n            activation=\"relu\",\n            input_shape=X_train.shape[1:],\n            kernel_initializer=\"lecun_normal\",\n        ),\n        keras.layers.BatchNormalization(),\n        keras.layers.Dense(20, activation=\"relu\", kernel_initializer=\"lecun_normal\"),\n        keras.layers.BatchNormalization(),\n        keras.layers.Dense(20, activation=\"relu\", kernel_initializer=\"lecun_normal\"),\n        keras.layers.BatchNormalization(),\n        keras.layers.Dense(1),\n    ]\n)\n\noptimizer = tf.keras.optimizers.Adam(learning_rate=0.1, beta_1=0.9, beta_2=0.999)\n\nmodel.compile(loss=\"mean_squared_error\", optimizer=optimizer)\ncheckpoint_cb = keras.callbacks.ModelCheckpoint(\n    \"my_keras_model.h5\", save_best_only=True\n)\nearly_stopping_cb = keras.callbacks.EarlyStopping(\n    patience=30, restore_best_weights=True\n)\n\nmodel.summary()\n\n# keras.utils.plot_model(model, show_shapes=True,) # to_file='dot_img.png', )\n\nhistory = model.fit(\n    X_train,\n    y_train,\n    epochs=250,\n    validation_split=0.2,\n    callbacks=[checkpoint_cb, early_stopping_cb],\n)\nmodel = keras.models.load_model(\"my_keras_model.h5\")\n\nprint(history.params)\n\npd.DataFrame(history.history).plot(figsize=(8, 5))\nplt.grid(True)\nplt.show()\n\ntrain_predictions = model.predict(X_train)\ntest_predictions = model.predict(X_test)\ntrain_predictions = np.ravel(train_predictions.T)\ntest_predictions = np.ravel(test_predictions.T)\nprint(test_predictions.shape)\n\nprint(\"\\n\\nTrain R2: %0.3f\" % (r2_score(train_predictions, y_train)))\nprint(\"Test R2: %0.3f\" % (r2_score(test_predictions, y_test)))\nprint(\"Predictions - Ground Truth (Kelvin): \", (test_predictions - y_test))\n\nfig = plt.figure(figsize=(12, 5))\n\nfig.add_subplot(121)\nsns.regplot(x=y_train, y=train_predictions, color=\"g\")\nplt.title(\"Train Data\", fontsize=16)\nplt.xlabel(\"Ground Truth\", fontsize=12)\nplt.ylabel(\"Predictions\", fontsize=12)\n\nfig.add_subplot(122)\nsns.regplot(x=y_test, y=test_predictions, color=\"g\")\nplt.title(\"Test/Unseen Data\", fontsize=16)\nplt.xlabel(\"Ground Truth\", fontsize=12)\nplt.ylabel(\"Predictions\", fontsize=12)\n\nplt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Show graph\n==========\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![Neural Network Validation Loss](../../_static/doe_ml_validation_loss.png){.align-center}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Neural Network Validation Loss\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![Neural Network Predictions](../../_static/doe_ml_predictions_neural_network.png){.align-center}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Neural Network Predictions\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}