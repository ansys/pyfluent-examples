{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# DOE-ML-Mixing-Elbow\nThese examples show you how you can use Fluent capabilities from Python to perform\nFluent simulations. This includes geometry import, Fluent's meshing workflows,\nsetting up and running the solver, and reviewing the results using Fluent's\npostprocessing capabilities.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Import modules\nimport ansys.fluent.core as pyfluent\nfrom ansys.fluent.core import examples\nimport matplotlib.pyplot as plt  # noqa: F401\nimport numpy as np\nimport pandas as pd  # noqa: F401\nimport plotly.graph_objects as go  # noqa: F401\nimport seaborn as sns  # noqa: F401\n\nimport_filename = examples.download_file(\n    \"elbow.cas.h5\", \"pyfluent/examples/DOE-ML-Mixing-Elbow\"\n)  # noqa: E501\n\n# Create a session object\nsession = pyfluent.launch_fluent()\n\n# Check server status\nsession.check_health()\n\n# Read a case file\nsession.tui.file.read_case(import_filename)\n\n# Define Manual DOE as numpy arrays\ncoldVelArr = np.array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7])\nhotVelArr = np.array([0.8, 1, 1.2, 1.4, 1.6, 1.8, 2.0])\nresArr = np.zeros((coldVelArr.shape[0], hotVelArr.shape[0]))\n\n# Run cases in sequence\n# Populate results (Mass Weighted Average of Temperature at Outlet) in resArr\nfor idx1, coldVel in np.ndenumerate(coldVelArr):\n    for idx2, hotVel in np.ndenumerate(hotVelArr):\n\n        inlet1 = session.setup.boundary_conditions.velocity_inlet[\"cold-inlet\"]\n        inlet1.vmag = coldVel\n\n        inlet2 = session.setup.boundary_conditions.velocity_inlet[\"hot-inlet\"]\n        inlet2.vmag = hotVel\n\n        session.solution.initialization()\n        session.tui.solve.iterate(5)  # 200\n\n        session.solution.report_definitions.surface[\"outlet-temp-avg\"] = {\n            \"report_type\": \"surface-massavg\",\n            \"surface_names\": [\"outlet\"],\n            \"field\": \"temperature\",\n        }\n\n        output = session.solution.report_definitions.compute(\n            report_defs=[\"outlet-temp-avg\"]\n        )\n\n        resArr[idx1][idx2] = output[0][\"outlet-temp-avg\"][0]\n\n# Define Manual DOE as numpy arrays\ncoldVelArr = np.array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7])\nhotVelArr = np.array([0.8, 1, 1.2, 1.4, 1.6, 1.8, 2.0])\nresArr = np.array(\n    [\n        [299.68665, 300.69921, 301.56705, 302.34852, 302.98525, 303.58664, 304.06953],\n        [297.05361, 297.80859, 298.4808, 299.10745, 299.6902, 300.22034, 300.70074],\n        [295.9343, 296.51279, 297.0535, 297.56171, 298.04696, 298.47616, 298.90577],\n        [295.31416, 295.7837, 296.22907, 296.65212, 297.05474, 297.43761, 297.80631],\n        [294.91981, 295.31458, 295.6923, 296.05425, 296.40156, 296.73504, 297.05574],\n        [294.64707, 294.9871, 295.31467, 295.63081, 295.9354, 296.23001, 296.51455],\n        [294.44734, 294.74565, 295.03459, 295.31482, 295.58626, 295.84967, 296.10494],\n    ]\n)\n\n# Define figure object\nfig = go.Figure(data=[go.Surface(z=resArr.T, x=coldVelArr, y=hotVelArr)])\n\n# Update figure layout\nfig.update_layout(\n    title={\n        \"text\": \"Mixing Elbow Response Surface\",\n        \"y\": 0.9,\n        \"x\": 0.5,\n        \"xanchor\": \"center\",\n        \"yanchor\": \"top\",\n    }\n)\n\nfig.update_layout(\n    scene=dict(\n        xaxis_title=\"Cold Inlet Vel (m/s)\",\n        yaxis_title=\"Hot Inlet Vel (m/s)\",\n        zaxis_title=\"Average Outlet Temperature (K)\",\n    ),\n    width=600,\n    height=600,\n    margin=dict(l=80, r=80, b=80, t=80),\n)\n# Show figure\nfig.show()\n\n# Create a dataframe\ndf = pd.DataFrame(columns=[\"coldVel\", \"hotVel\", \"Result\"])\n\n# Add temperatures to dataframe\nfor idx1, coldVel in np.ndenumerate(coldVelArr):\n    for idx2, hotVel in np.ndenumerate(hotVelArr):\n        tempDict = {\n            \"coldVel\": coldVel,\n            \"hotVel\": hotVel,\n            \"Result\": resArr[idx1][idx2],\n        }  # noqa: E501\n        df = df.append(tempDict, ignore_index=True)\n\nfrom sklearn.compose import ColumnTransformer\n\n# Import modules\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import PolynomialFeatures, StandardScaler\n\n# Define polynomial features\npoly_features = PolynomialFeatures(degree=1, include_bias=False)\n\n# Define pipeline\ntransformer1 = Pipeline(\n    [\n        (\"poly_features\", poly_features),\n        (\"std_scaler\", StandardScaler()),\n    ]\n)\n\n# Apply column wise transformations\nx_ct = ColumnTransformer(\n    [\n        (\"transformer1\", transformer1, [\"coldVel\", \"hotVel\"]),\n    ],\n    remainder=\"drop\",\n)\n\n# Train-test split\ntrain_set, test_set = train_test_split(df, test_size=0.2, random_state=42)\n\n# Transform train and test dataset\nX_train = x_ct.fit_transform(train_set)\nX_test = x_ct.fit_transform(test_set)\n\ny_train = train_set[\"Result\"]\ny_test = test_set[\"Result\"]\ny_train = np.ravel(y_train.T)\ny_test = np.ravel(y_test.T)\n\n# from pprint import pprint\nfrom sklearn.metrics import r2_score\n\n# Import requirements\n# from sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import RepeatedKFold, cross_val_score\n\n# from sklearn.ensemble import RandomForestRegressor\nfrom xgboost import XGBRegressor\n\n# Set precision level\nnp.set_printoptions(precision=2)\n\n# Function to display scores\ndef display_scores(scores):\n    print(\"\\nCross-Validation Scores:\", scores)\n    print(\"Mean:%0.2f\" % (scores.mean()))\n    print(\"Std. Dev.:%0.2f\" % (scores.std()))\n\n\n# Function to fit the model and predict on test data set\ndef fit_and_predict(model):\n    cv = RepeatedKFold(n_splits=5, n_repeats=3, random_state=42)\n    cv_scores = cross_val_score(\n        model, X_train, y_train, scoring=\"neg_mean_squared_error\", cv=cv\n    )\n    rmse_scores = np.sqrt(-cv_scores)\n    display_scores(rmse_scores)\n\n    model.fit(X_train, y_train)\n    train_predictions = model.predict(X_train)\n    test_predictions = model.predict(X_test)\n    print(\"\\n\\nCoefficient Of Determination\")\n    print(\"Train Data R2 Score: %0.3f\" % (r2_score(train_predictions, y_train)))\n    print(\"Test Data R2 Score: %0.3f\" % (r2_score(test_predictions, y_test)))\n    print(\n        \"\\n\\nPredictions - Ground Truth (Kelvin): \", (test_predictions - y_test), \"\\n\"\n    )\n    #    print(\"\\n\\nModel Parameters:\")\n    #    pprint(model.get_params())\n\n    fig = plt.figure(figsize=(12, 5))\n\n    fig.add_subplot(121)\n    sns.regplot(x=y_train, y=train_predictions, color=\"g\")\n    plt.title(\"Train Data\", fontsize=16)\n    plt.xlabel(\"Ground Truth\", fontsize=12)\n    plt.ylabel(\"Predictions\", fontsize=12)\n\n    fig.add_subplot(122)\n    sns.regplot(x=y_test, y=test_predictions, color=\"g\")\n    plt.title(\"Test/Unseen Data\", fontsize=16)\n    plt.xlabel(\"Ground Truth\", fontsize=12)\n    plt.ylabel(\"Predictions\", fontsize=12)\n\n    plt.tight_layout()\n    plt.show()\n\n\n# Define model object\n# model = LinearRegression()\nmodel = XGBRegressor(\n    n_estimators=100, max_depth=10, eta=0.3, subsample=0.8, random_state=42\n)\n# model = RandomForestRegressor(random_state=42)\n\n# Fit the model and predict on test data set\nfit_and_predict(model)\n\n# Import modules\nimport tensorflow as tf\nfrom tensorflow import keras\n\nprint(\"TensorFlow version is:\", tf.__version__)\nkeras.backend.clear_session()\nnp.random.seed(42)\ntf.random.set_seed(42)\n\n# Define Sequential model\nmodel = keras.models.Sequential(\n    [\n        keras.layers.Dense(\n            10,\n            activation=\"relu\",\n            input_shape=X_train.shape[1:],\n            kernel_initializer=\"lecun_normal\",\n        ),\n        keras.layers.BatchNormalization(),\n        keras.layers.Dense(10, activation=\"relu\", kernel_initializer=\"lecun_normal\"),\n        keras.layers.BatchNormalization(),\n        keras.layers.Dense(1),\n    ]\n)\n\n# Optimize the model\noptimizer = tf.keras.optimizers.Adam(lr=0.1, beta_1=0.9, beta_2=0.999)\n\n# Compile the model\nmodel.compile(loss=\"mean_squared_error\", optimizer=optimizer)\ncheckpoint_cb = keras.callbacks.ModelCheckpoint(\n    \"my_keras_model.h5\", save_best_only=True\n)\nearly_stopping_cb = keras.callbacks.EarlyStopping(\n    patience=30, restore_best_weights=True\n)\n\n# Print model summary\nmodel.summary()\n\n# keras.utils.plot_model(model, show_shapes=True,) # to_file='dot_img.png', )\n\n# Train model\nhistory = model.fit(\n    X_train,\n    y_train,\n    epochs=250,\n    validation_split=0.2,\n    callbacks=[checkpoint_cb, early_stopping_cb],\n)\nmodel = keras.models.load_model(\"my_keras_model.h5\")\n\n# Print training parameters\nprint(history.params)\n\n# Plot figures based on model history\npd.DataFrame(history.history).plot(figsize=(8, 5))\nplt.grid(True)\nplt.show()\n\n# Define train test predictions\ntrain_predictions = model.predict(X_train)\ntest_predictions = model.predict(X_test)\ntrain_predictions = np.ravel(train_predictions.T)\ntest_predictions = np.ravel(test_predictions.T)\n\n# Print Accuracy\nprint(\"\\n\\nTrain R2: %0.3f\" % (r2_score(train_predictions, y_train)))\nprint(\"Test R2: %0.3f\" % (r2_score(test_predictions, y_test)))\nprint(\"Predictions - Ground Truth (Kelvin): \", (test_predictions - y_test))\n\n# Plot figures\nfig = plt.figure(figsize=(12, 5))\n\nfig.add_subplot(121)\nsns.regplot(x=y_train, y=train_predictions, color=\"g\")\nplt.title(\"Train\", fontsize=16)\nplt.xlabel(\"Ground Truth\", fontsize=12)\nplt.ylabel(\"Predictions\", fontsize=12)\n\nfig.add_subplot(122)\nsns.regplot(x=y_test, y=test_predictions, color=\"g\")\nplt.title(\"Test\", fontsize=16)\nplt.xlabel(\"Ground Truth\", fontsize=12)\nplt.ylabel(\"Predictions\", fontsize=12)\n\nplt.tight_layout()\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}